{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheOnesThatWereAbroad/Assignment1/blob/main/POS_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc8x9pA00Sfd"
      },
      "source": [
        "# Assignment 1 - POS tagging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6A9uR7hGmZvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "jHhrkDf2kqzg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
        "\n",
        "from data_input import DataInput\n",
        "from text_vectorizer import TextVectorizer, TargetVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "W54o7ygSsHDI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx2qo48Ikqzi"
      },
      "source": [
        "## 1. Build a dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN34sX55kqzi"
      },
      "source": [
        "### 1.1 Dataset preparation\n",
        "For this experiment, the [Dependency Parsed Treebank](https://www.nltk.org/nltk_data/) dataset is used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRQ_hwv9mHtK",
        "outputId": "425650a5-4c57-4373-adb7-cc32f5abfde9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/data_input.py:117: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(X), np.array(y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 1957\n",
            "Dev set size: 979\n",
            "Test set size: 978\n"
          ]
        }
      ],
      "source": [
        "# download the dataset and split it into train, dev and test sets\n",
        "dataset = DataInput(\n",
        "        data_url=\"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\",\n",
        "        train_size=0.50,\n",
        "        dev_size=0.25,\n",
        "        dataset_folder=os.path.join(os.getcwd(), \"dataset\"),\n",
        "        split_into_sentences=True,\n",
        "        shuffle=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGQatFzWkqzk"
      },
      "source": [
        "Pre-processing is always an important step with which start. There are a lot of pre-processing steps that we can consider, but for this experiment the only pre-processing operation performed is:\n",
        "- **to lower**, in part-of-speech tagging scenario casing of the input tokens is crucial to find the correspondent token in the embedding vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "YbVR94oskqzk"
      },
      "outputs": [],
      "source": [
        "# do preprocessing for train, validation and test sets\n",
        "dataset.preprocessing(\"train\", to_lower=True)\n",
        "dataset.preprocessing(\"dev\", to_lower=True)\n",
        "dataset.preprocessing(\"test\", to_lower=True)\n",
        "\n",
        "# separate inputs and targets\n",
        "X_train, y_train = dataset.train\n",
        "X_dev, y_dev = dataset.dev\n",
        "X_test, y_test = dataset.test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxfgDx0jrnqV",
        "outputId": "75a657fb-b767-4dcd-cb04-c1ced79081da"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([array(['commonwealth', 'edison', 'co.', 'was', 'ordered', 'to', 'refund',\n",
              "              'about', '$', '250', 'million', 'to', 'its', 'current', 'and',\n",
              "              'former', 'ratepayers', 'for', 'illegal', 'rates', 'collected',\n",
              "              'for', 'cost', 'overruns', 'on', 'a', 'nuclear', 'power', 'plant',\n",
              "              '.'], dtype='<U12')                                               ,\n",
              "       array(['the', 'refund', 'was', 'about', '$', '55', 'million', 'more',\n",
              "              'than', 'previously', 'ordered', 'by', 'the', 'illinois',\n",
              "              'commerce', 'commission', 'and', 'trade', 'groups', 'said', 'it',\n",
              "              'may', 'be', 'the', 'largest', 'ever', 'required', 'of', 'a',\n",
              "              'state', 'or', 'local', 'utility', '.'], dtype='<U10')           ,\n",
              "       array(['state', 'court', 'judge', 'richard', 'curry', 'ordered', 'edison',\n",
              "              'to', 'make', 'average', 'refunds', 'of', 'about', '$', '45', 'to',\n",
              "              '$', '50', 'each', 'to', 'edison', 'customers', 'who', 'have',\n",
              "              'received', 'electric', 'service', 'since', 'april', '1986', ',',\n",
              "              'including', 'about', 'two', 'million', 'customers', 'who', 'have',\n",
              "              'moved', 'during', 'that', 'period', '.'], dtype='<U9')            ,\n",
              "       ...,\n",
              "       array(['indexing', '--', 'many', 'investors', ',', 'mainly',\n",
              "              'institutions', ',', 'follow', 'an', 'investment', 'strategy',\n",
              "              'of', 'buying', 'and', 'holding', 'a', 'mix', 'of', 'stocks', 'to',\n",
              "              'match', 'the', 'performance', 'of', 'a', 'broad', 'stock-market',\n",
              "              'barometer', 'such', 'as', 'the', 's&p', '500', '.'], dtype='<U12'),\n",
              "       array(['many', 'institutional', 'index', 'funds', 'are', 'active',\n",
              "              'program', 'traders', ',', 'swapping', 'their', 'stocks', 'for',\n",
              "              'futures', 'when', 'profitable', 'to', 'do', 'so', '.'],\n",
              "             dtype='<U13')                                                    ,\n",
              "       array(['program', 'trading', '--', 'a', 'wide', 'range', 'of',\n",
              "              'computer-assisted', 'portfolio', 'trading', 'strategies',\n",
              "              'involving', 'the', 'simultaneous', 'purchase', 'or', 'sale', 'of',\n",
              "              '15', 'or', 'more', 'stocks', '.'], dtype='<U17')                  ],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPv-M1xEmHtM"
      },
      "source": [
        "### 1.2 Dataset analysis\n",
        "Let's take a look at the dataset, to inspect the distribution of the POS tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Oh9Jg3ePkqzm"
      },
      "outputs": [],
      "source": [
        "def get_occurences(data, ordered=False, exclude=[]):\n",
        "    \"\"\"\n",
        "    Get the occurences of each token in the data.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : list of np arrays, representing the data to get the occurences from\n",
        "    ordered : bool, if True, the occurences will be returned in descending order\n",
        "    exclude : list of strings, tokens that should not be included in the occurences\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    occurences : dict, mapping each token to the number of occurences\n",
        "    \"\"\"\n",
        "    tokens, counts = np.unique(np.concatenate(data), return_counts=True)\n",
        "    occurences = dict(zip(tokens, counts))\n",
        "\n",
        "    if len(exclude) > 0:\n",
        "        for token in exclude:\n",
        "            if token in occurences:\n",
        "                del occurences[token]\n",
        "\n",
        "    if ordered:\n",
        "        occurences = dict(sorted(occurences.items(), key=lambda x: x[1], reverse=True))\n",
        "    return occurences\n",
        "\n",
        "# get the occurences of each POS tag in the three sets withouth the PUNCTUATION class \".\"\n",
        "train_tags_occ = get_occurences(y_train, ordered=True, exclude=[\".\"])\n",
        "dev_tags_occ = get_occurences(y_dev, exclude=[\".\"])\n",
        "test_tags_occ = get_occurences(y_test, exclude=[\".\"])\n",
        "\n",
        "# build a matrix of the occurences of size (n_tags, 3)\n",
        "tags_occ = np.array([[v, dev_tags_occ[k], test_tags_occ[k]] if k in dev_tags_occ and k in test_tags_occ else [v, dev_tags_occ[k], 0] if k in dev_tags_occ else [v, 0, test_tags_occ[k]] if k in test_tags_occ else [v, 0, 0] for k, v in train_tags_occ.items()])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X29po_W5wdWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "aZh5QAJIkqzn",
        "outputId": "b79b83a5-4150-4bcc-972a-09f392095d9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1656x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot bar chart of the occurences of each POS tag\n",
        "fig, ax = plt.subplots(1, 1, figsize=(23, 8))\n",
        "tags = list(train_tags_occ.keys())\n",
        "ax.bar(tags, tags_occ[:, 1], width=0.3, align='edge', label='dev')\n",
        "ax.bar(tags, tags_occ[:, 2], width=-0.6, align='edge', label='test')\n",
        "ax.bar(tags, tags_occ[:, 0], width=-0.3, align='edge', label='train')\n",
        "ax.set_xticks(tags)\n",
        "ax.set_xlabel('Tags')\n",
        "ax.set_ylabel('Occurences')\n",
        "ax.set_title(\"Occurences of POS tags\")\n",
        "ax.legend()\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYCqD_Zpkqzo",
        "outputId": "a7f90aa7-c0a8-4a1b-a84c-ebac77026ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following tags (from the train set) are not in the dev set: {'#'}\n",
            "The following tags (from the train set) are not in the test set: {'FW'}\n",
            "The following tags (from the dev set) are not in the train set: {'UH', 'LS'}\n",
            "The following tags (from the test set) are not in the train set: {'LS', 'SYM'}\n"
          ]
        }
      ],
      "source": [
        "# analyze the difference between the presence of the POS tags in the train, dev and test sets\n",
        "train_tags_not_dev = set(train_tags_occ.keys()) - set(dev_tags_occ.keys())\n",
        "train_tags_not_test = set(train_tags_occ.keys()) - set(test_tags_occ.keys())\n",
        "dev_tags_not_train = set(dev_tags_occ.keys()) - set(train_tags_occ.keys())\n",
        "test_tags_not_train = set(test_tags_occ.keys()) - set(train_tags_occ.keys())\n",
        "\n",
        "if(len(train_tags_not_dev) > 0):\n",
        "    print(\"The following tags (from the train set) are not in the dev set:\", train_tags_not_dev)\n",
        "if(len(train_tags_not_test) > 0):\n",
        "    print(\"The following tags (from the train set) are not in the test set:\", train_tags_not_test)\n",
        "if(len(dev_tags_not_train) > 0):\n",
        "    print(\"The following tags (from the dev set) are not in the train set:\", dev_tags_not_train)\n",
        "if(len(test_tags_not_train) > 0):\n",
        "    print(\"The following tags (from the test set) are not in the train set:\", test_tags_not_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkIYSNxukqzo"
      },
      "source": [
        "### 1.3 GloVe embeddings vectorization\n",
        "The next step consists in downloading a pre-trained embedding model, namely GloVe. It is a techniques that tries to encoded global semantic properties based on the co-occurrence matrix.\n",
        "Three different dimensional space versions are available: 50, 100, 200.\n",
        "\n",
        "From the choosen embedding, a starting vocabulary is built.\n",
        "Then this vocabulary is enriched with the embeddings computed for the OOV words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxU2LR1Bkqzp",
        "outputId": "2e2f9d28-0e1a-4eea-8bf7-4b113d0ef20f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing the training set...\n",
            "Generated embeddings for 329 OOV words.\n",
            "\n",
            "Parsing the validation set...\n",
            "Generated embeddings for 170 OOV words.\n",
            "\n",
            "Parsing the test set...\n",
            "Generated embeddings for 177 OOV words.\n"
          ]
        }
      ],
      "source": [
        "# initialize the vectorizer for the input tokens to convert them to embedding vectors\n",
        "# and build the vocabulary V1 from the glove embeddings\n",
        "text_vectorizer = TextVectorizer(\n",
        "    glove_url=\"http://nlp.stanford.edu/data/glove.6B.zip\",\n",
        "    max_tokens=20000,\n",
        "    embedding_dim=50,\n",
        "    embedding_folder=os.path.join(os.getcwd(), \"glove\")\n",
        ")\n",
        "\n",
        "# compute embeddings for terms (OOV1) in the training set that are out of vocabulary V1 and add them: V2=V1+OOV1\n",
        "print(\"Parsing the training set...\")\n",
        "text_vectorizer.adapt(X_train)\n",
        "# use the vocabulary V2 to convert the training set inputs into embedding vectors\n",
        "X_train = text_vectorizer.transform(X_train)\n",
        "\n",
        "# compute embeddings for terms (OOV2) in the validation set that are out of vocabulary V2 and add them: V3=V2+OOV2\n",
        "print(\"\\nParsing the validation set...\")\n",
        "text_vectorizer.adapt(X_dev)\n",
        "# use the vocabulary V3 to convert the validation set inputs into embedding vectors\n",
        "X_dev = text_vectorizer.transform(X_dev)\n",
        "\n",
        "# compute embeddings for terms (OOV3) in the test set that are out of vocabulary V3 and add them: V4=V3+OOV3\n",
        "print(\"\\nParsing the test set...\")\n",
        "text_vectorizer.adapt(X_test)\n",
        "# use the vocabulary V4 to convert the test set inputs into embedding vectors\n",
        "X_test = text_vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9lB8KL8rhD9",
        "outputId": "2905b5e7-a9af-4801-981d-5af8f947684b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.28550005,  0.48245001, -0.70515001, ..., -0.22515   ,\n",
              "        -0.14159   , -0.7669    ],\n",
              "       [ 0.25810999,  0.23231   ,  0.74949002, ..., -0.18379   ,\n",
              "         0.13196   ,  0.28165999],\n",
              "       [ 0.15121999, -0.065602  ,  0.41077   , ...,  0.17369001,\n",
              "        -0.090891  ,  0.94072998],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "NwDnKWdckqzp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f51b770-b9de-4600-fde1-527aa77aea8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (1957, 300, 50)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Input shape: {X_train.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiDdPTFrkqzp"
      },
      "source": [
        "### 1.4 One-hot encoding of the targets\n",
        "Each POS tag in each set is converted using the one-hot representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "C37qdVk7kqzq"
      },
      "outputs": [],
      "source": [
        "# initialize the vectorizer for the target tags to convert them into one-hot representation\n",
        "target_vectorizer = TargetVectorizer(300)\n",
        "\n",
        "# adapt the target vectorizer with only the training set: we do not consider possible targets that are not seen in training set but they are in the dev/test set\n",
        "target_vectorizer.adapt(y_train)  \n",
        "\n",
        "# convert the targets into one-hot representation for each splitting set\n",
        "y_train = target_vectorizer.transform(y_train)\n",
        "y_dev = target_vectorizer.transform(y_dev)\n",
        "y_test = target_vectorizer.transform(y_test)\n",
        "\n",
        "n_classes = y_train[0].shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "qnH7e4okkqzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f50c335-5ef6-47d6-cbd5-de1efa446156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target shape: (1957, 300, 42)\n",
            "Number of classes for one-hot encoded targets: 42\n"
          ]
        }
      ],
      "source": [
        "print(f\"Target shape: {y_train.shape}\")\n",
        "print(f\"Number of classes for one-hot encoded targets: {n_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khILeN7fkqzq"
      },
      "source": [
        "## 2. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZfQ0dECkqzr"
      },
      "source": [
        "### 2.1 Models definition\n",
        "We are now ready to define our neural network architectures!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "FbI93ctVkqzr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b70f7be-92a8-4a3d-eba4-22024f22d8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " padding_masking (Masking)   (1957, 300, 50)           0         \n",
            "                                                                 \n",
            " bilstm_1 (Bidirectional)    (1957, 300, 128)          58880     \n",
            "                                                                 \n",
            " output (Dense)              (1957, 300, 42)           5418      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,298\n",
            "Trainable params: 64,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def create_model(layers_info, compile_info):\n",
        "    \"\"\"\n",
        "    Create a Keras model given a list of layer information\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    layers_info : a list of dictionaries, one for each layer\n",
        "    compile_info : dictionary containing compile information\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model: the built keras sequential model\n",
        "    \"\"\"\n",
        "\n",
        "    model = keras.Sequential()\n",
        "    for info in layers_info:\n",
        "        layer = info['layer_name'](**{key: value for key, value in info.items() if key != 'layer_name'})\n",
        "        model.add(layer)\n",
        "\n",
        "    # Compile\n",
        "    model.compile(**compile_info)\n",
        "\n",
        "    return model\n",
        "\n",
        "layers_info = [\n",
        "    {\n",
        "        \"layer_name\": layers.Masking,\n",
        "        \"name\": \"padding_masking\",\n",
        "        \"mask_value\": 0.\n",
        "    },\n",
        "    {\n",
        "        'layer_name': layers.Bidirectional,\n",
        "        \"layer\": layers.LSTM(64, return_sequences=True),\n",
        "        \"name\": \"bilstm_1\",\n",
        "    },\n",
        "    {\n",
        "        \"layer_name\": layers.Dense,\n",
        "        \"units\": n_classes,\n",
        "        \"activation\": \"softmax\",\n",
        "        \"name\": \"output\"\n",
        "    }\n",
        "]\n",
        "\n",
        "compile_info = {\n",
        "    'optimizer': keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    'loss': 'categorical_crossentropy',\n",
        "    'metrics' : [\"accuracy\"]\n",
        "}\n",
        "\n",
        "model = create_model(layers_info, compile_info)\n",
        "model.build(input_shape=X_train.shape)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWdZM3rskqzr"
      },
      "source": [
        "### 2.2 Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "mG4rYoHDmHtO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "041b5b3a-e6b1-415a-c760-086f36f390de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "127/164 [======================>.......] - ETA: 1s - loss: 0.2003 - accuracy: 0.3641"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-272917c7c9d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_bilstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history_bilstm = model.fit(X_train, y_train, epochs=20, batch_size=12, validation_data=(X_dev, y_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab9ETsbC2Q82"
      },
      "source": [
        "### 2.3 History of the training\n",
        "Plot metrics evolution for each epoch during the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25YBLK3E2R6m"
      },
      "outputs": [],
      "source": [
        "def plot_history(models_history, keys, model_names=[], labels=(\"epochs\", \"metrics\"), figsize=(10,5), cmap='rainbow'):\n",
        "    \"\"\"\n",
        "    Plot the history of the metrics in the history dictionary for each model.\n",
        "        :param models_history: array of dictionary of the metric history for each model\n",
        "        :param keys: list of keys of the metrics to plot\n",
        "        :param model_names: list of names of the models\n",
        "        :param labels: list of labels of the axes\n",
        "        :param figsize: size of the figure\n",
        "        :param cmap: color map used for the plot\n",
        "    \"\"\"\n",
        "\n",
        "    # maps each model to a distinct RGB color\n",
        "    cmap = plt.cm.get_cmap(cmap, len(models_history))\n",
        "\n",
        "    \n",
        "    fig = plt.figure(figsize=figsize)\n",
        "\n",
        "    # for each model trained\n",
        "    for i, history in enumerate(models_history):\n",
        "        # take all pairs of training and val metrics\n",
        "        for j in range(0, len(keys), 2):\n",
        "            metric, val_metric = keys[j], keys[j+1]\n",
        "            \n",
        "            plt.plot(history[metric], label=f\"{model_names[i]} {metric}\", linestyle=\"solid\", color=cmap(i))\n",
        "            plt.plot(history[val_metric],  label=f\"{model_names[i]} {val_metric}\", linestyle=\"--\",  color=cmap(i))\n",
        "        \n",
        "    plt.xlabel(labels[0])\n",
        "    plt.ylabel(labels[1])\n",
        "\n",
        "    # Adding legend\n",
        "    plt.legend(\n",
        "          title =\"Legend\",\n",
        "          loc =\"upper left\",\n",
        "          bbox_to_anchor =(1.0, 0, 0.5, 1))\n",
        "    plt.title(\"Training history\")\n",
        "    plt.grid(linestyle='--', linewidth=1)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca9TMoj42VgT"
      },
      "outputs": [],
      "source": [
        "models_history = [history_bilstm.history]\n",
        "model_names = [\"BiLSTM\"]\n",
        "plot_history(models_history, keys=['loss', 'val_loss'], model_names=model_names, labels=(\"epochs\", \"loss\"), figsize=(15,7))\n",
        "plot_history(models_history, keys=['accuracy', 'val_accuracy'], model_names=model_names, labels=(\"epochs\", \"accuracy\"), figsize=(15,7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmIWLatvkqzt"
      },
      "source": [
        "## 3. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q71LkwAPkqzt"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_test, y_test, labels):\n",
        "    \"\"\"\n",
        "    given a trained model and a test set returns the f-score and the confusion matrix\n",
        "    taking into account only classes in labels\n",
        "    \"\"\"\n",
        "    raw_y_true = np.array(y_test)\n",
        "    raw_y_pred = model.predict(X_test)\n",
        "    # shape of the output is doc x len_sen x classes\n",
        "    # argmax for label predictions\n",
        "    len_sentence = raw_y_pred.shape[1]\n",
        "    num_sentences = raw_y_pred.shape[0]\n",
        "    y_pred = np.empty((num_sentences, len_sentence))\n",
        "    y_true = np.empty((num_sentences, len_sentence))\n",
        "    # assign label with the highest probability\n",
        "    for i in range(num_sentences):\n",
        "        for j in range(len_sentence):\n",
        "            y_pred[i,j] = np.argmax(raw_y_pred[i,j,:])\n",
        "            y_true[i,j] = np.argmax(raw_y_true[i,j,:])\n",
        "    # flatten the numpy array to have a 1D array\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "    # show confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    disp = ConfusionMatrixDisplay(conf_matrix)\n",
        "    disp.plot()\n",
        "    plt.show()\n",
        "    # f1 score\n",
        "    print(\"F score:\\n-------------------------------\\n\")\n",
        "    print(f1_score(y_true, y_pred, labels=labels, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua2c1KdCkqzt"
      },
      "outputs": [],
      "source": [
        "punctuation_indexes = [0, 1, 2, 3, 4, 5, 6, 16, 30, 43]\n",
        "classes = target_vectorizer.get_classes()\n",
        "valid_labels = list(set(range(len(classes))) - set(punctuation_indexes))\n",
        "evaluate_model(model, X_test, y_test, valid_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFaG0yb4kqzu"
      },
      "outputs": [],
      "source": [
        "i_test = 0  # change this to see the prediction for a different sentence\n",
        "\n",
        "print(\"Original POS tagging: \",target_vectorizer.inverse_transform([y_test[i_test]])[0])\n",
        "\n",
        "raw_y_pred = model.predict(np.array([X_test[i_test]]))\n",
        "# shape of the output is doc x len_sen x classes\n",
        "# argmax for label predictions\n",
        "n_class =  raw_y_pred.shape[2]\n",
        "len_sentence = raw_y_pred.shape[1]\n",
        "num_sentences = raw_y_pred.shape[0]\n",
        "\n",
        "# assign label with the highest probability\n",
        "y_pred = np.array([[1 if raw_y_pred[0,i,j] == max(raw_y_pred[0,i,:]) else 0 for j in range(n_class)] for i in range(len_sentence) ])\n",
        "print(\"Predicted POS tagging: \",target_vectorizer.inverse_transform([y_pred])[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of POS_tagging.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "63e28586807c6502c782d898cf9a0cc5787bb3d77952b17b51ec8bdcd4044a3d"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}