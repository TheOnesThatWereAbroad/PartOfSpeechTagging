{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.grammar import DependencyGrammar\n",
    "from nltk.parse.dependencygraph import DependencyGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package dependency_treebank to\n",
      "[nltk_data]     /Users/simone/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/dependency_treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('dependency_treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(will\n",
      "  (Vinken Pierre , (old (years 61)) ,)\n",
      "  (join (board the) (as (director a nonexecutive)) (Nov. 29))\n",
      "  .)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import dependency_treebank\n",
    "t = dependency_treebank.parsed_sents()\n",
    "print(t[0].tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can download the GloVe embeddings to vectorize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-09 14:17:09--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2022-03-09 14:17:09--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2022-03-09 14:17:10--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822,24M  5,18MB/s    in 2m 42s  \n",
      "\n",
      "2022-03-09 14:19:52 (5,07 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wsj_0095.dp',\n",
       " 'wsj_0184.dp',\n",
       " 'wsj_0177.dp',\n",
       " 'wsj_0037.dp',\n",
       " 'wsj_0126.dp',\n",
       " 'wsj_0066.dp',\n",
       " 'wsj_0052.dp',\n",
       " 'wsj_0112.dp',\n",
       " 'wsj_0003.dp',\n",
       " 'wsj_0143.dp',\n",
       " 'wsj_0153.dp',\n",
       " 'wsj_0013.dp',\n",
       " 'wsj_0102.dp',\n",
       " 'wsj_0042.dp',\n",
       " 'wsj_0076.dp',\n",
       " 'wsj_0136.dp',\n",
       " 'wsj_0027.dp',\n",
       " 'wsj_0167.dp',\n",
       " 'wsj_0194.dp',\n",
       " 'wsj_0085.dp',\n",
       " 'wsj_0007.dp',\n",
       " 'wsj_0147.dp',\n",
       " 'wsj_0056.dp',\n",
       " 'wsj_0116.dp',\n",
       " 'wsj_0180.dp',\n",
       " 'wsj_0091.dp',\n",
       " 'wsj_0122.dp',\n",
       " 'wsj_0062.dp',\n",
       " 'wsj_0173.dp',\n",
       " 'wsj_0033.dp',\n",
       " 'wsj_0023.dp',\n",
       " 'wsj_0163.dp',\n",
       " 'wsj_0072.dp',\n",
       " 'wsj_0132.dp',\n",
       " 'wsj_0081.dp',\n",
       " 'wsj_0190.dp',\n",
       " 'wsj_0106.dp',\n",
       " 'wsj_0046.dp',\n",
       " 'wsj_0157.dp',\n",
       " 'wsj_0017.dp',\n",
       " 'wsj_0006.dp',\n",
       " 'wsj_0146.dp',\n",
       " 'wsj_0057.dp',\n",
       " 'wsj_0117.dp',\n",
       " 'wsj_0181.dp',\n",
       " 'wsj_0090.dp',\n",
       " 'wsj_0123.dp',\n",
       " 'wsj_0063.dp',\n",
       " 'wsj_0172.dp',\n",
       " 'wsj_0032.dp',\n",
       " 'wsj_0022.dp',\n",
       " 'wsj_0162.dp',\n",
       " 'wsj_0073.dp',\n",
       " 'wsj_0133.dp',\n",
       " 'wsj_0080.dp',\n",
       " 'wsj_0191.dp',\n",
       " 'wsj_0107.dp',\n",
       " 'wsj_0047.dp',\n",
       " 'wsj_0156.dp',\n",
       " 'wsj_0016.dp',\n",
       " 'wsj_0094.dp',\n",
       " 'wsj_0185.dp',\n",
       " 'wsj_0176.dp',\n",
       " 'wsj_0036.dp',\n",
       " 'wsj_0127.dp',\n",
       " 'wsj_0067.dp',\n",
       " 'wsj_0053.dp',\n",
       " 'wsj_0113.dp',\n",
       " 'wsj_0002.dp',\n",
       " 'wsj_0142.dp',\n",
       " 'wsj_0152.dp',\n",
       " 'wsj_0012.dp',\n",
       " 'wsj_0103.dp',\n",
       " 'wsj_0043.dp',\n",
       " 'wsj_0077.dp',\n",
       " 'wsj_0137.dp',\n",
       " 'wsj_0026.dp',\n",
       " 'wsj_0166.dp',\n",
       " 'wsj_0195.dp',\n",
       " 'wsj_0084.dp',\n",
       " 'wsj_0058.dp',\n",
       " 'wsj_0118.dp',\n",
       " 'wsj_0009.dp',\n",
       " 'wsj_0149.dp',\n",
       " 'wsj_0159.dp',\n",
       " 'wsj_0019.dp',\n",
       " 'wsj_0108.dp',\n",
       " 'wsj_0048.dp',\n",
       " 'wsj_0128.dp',\n",
       " 'wsj_0068.dp',\n",
       " 'wsj_0179.dp',\n",
       " 'wsj_0039.dp',\n",
       " 'wsj_0029.dp',\n",
       " 'wsj_0169.dp',\n",
       " 'wsj_0078.dp',\n",
       " 'wsj_0138.dp',\n",
       " 'wsj_0129.dp',\n",
       " 'wsj_0069.dp',\n",
       " 'wsj_0178.dp',\n",
       " 'wsj_0038.dp',\n",
       " 'wsj_0028.dp',\n",
       " 'wsj_0168.dp',\n",
       " 'wsj_0079.dp',\n",
       " 'wsj_0139.dp',\n",
       " 'wsj_0059.dp',\n",
       " 'wsj_0119.dp',\n",
       " 'wsj_0008.dp',\n",
       " 'wsj_0148.dp',\n",
       " 'wsj_0158.dp',\n",
       " 'wsj_0018.dp',\n",
       " 'wsj_0109.dp',\n",
       " 'wsj_0049.dp',\n",
       " 'wsj_0099.dp',\n",
       " 'wsj_0188.dp',\n",
       " 'wsj_0198.dp',\n",
       " 'wsj_0089.dp',\n",
       " 'wsj_0098.dp',\n",
       " 'wsj_0189.dp',\n",
       " 'wsj_0199.dp',\n",
       " 'wsj_0088.dp',\n",
       " 'wsj_0054.dp',\n",
       " 'wsj_0114.dp',\n",
       " 'wsj_0005.dp',\n",
       " 'wsj_0145.dp',\n",
       " 'wsj_0171.dp',\n",
       " 'wsj_0031.dp',\n",
       " 'wsj_0120.dp',\n",
       " 'wsj_0060.dp',\n",
       " 'wsj_0093.dp',\n",
       " 'wsj_0182.dp',\n",
       " 'wsj_0192.dp',\n",
       " 'wsj_0083.dp',\n",
       " 'wsj_0070.dp',\n",
       " 'wsj_0130.dp',\n",
       " 'wsj_0021.dp',\n",
       " 'wsj_0161.dp',\n",
       " 'wsj_0155.dp',\n",
       " 'wsj_0015.dp',\n",
       " 'wsj_0104.dp',\n",
       " 'wsj_0044.dp',\n",
       " 'wsj_0124.dp',\n",
       " 'wsj_0064.dp',\n",
       " 'wsj_0175.dp',\n",
       " 'wsj_0035.dp',\n",
       " 'wsj_0186.dp',\n",
       " 'wsj_0097.dp',\n",
       " 'wsj_0001.dp',\n",
       " 'wsj_0141.dp',\n",
       " 'wsj_0050.dp',\n",
       " 'wsj_0110.dp',\n",
       " 'wsj_0100.dp',\n",
       " 'wsj_0040.dp',\n",
       " 'wsj_0151.dp',\n",
       " 'wsj_0011.dp',\n",
       " 'wsj_0087.dp',\n",
       " 'wsj_0196.dp',\n",
       " 'wsj_0025.dp',\n",
       " 'wsj_0165.dp',\n",
       " 'wsj_0074.dp',\n",
       " 'wsj_0134.dp',\n",
       " 'wsj_0125.dp',\n",
       " 'wsj_0065.dp',\n",
       " 'wsj_0174.dp',\n",
       " 'wsj_0034.dp',\n",
       " 'wsj_0187.dp',\n",
       " 'wsj_0096.dp',\n",
       " 'wsj_0140.dp',\n",
       " 'wsj_0051.dp',\n",
       " 'wsj_0111.dp',\n",
       " 'wsj_0101.dp',\n",
       " 'wsj_0041.dp',\n",
       " 'wsj_0150.dp',\n",
       " 'wsj_0010.dp',\n",
       " 'wsj_0086.dp',\n",
       " 'wsj_0197.dp',\n",
       " 'wsj_0024.dp',\n",
       " 'wsj_0164.dp',\n",
       " 'wsj_0075.dp',\n",
       " 'wsj_0135.dp',\n",
       " 'wsj_0055.dp',\n",
       " 'wsj_0115.dp',\n",
       " 'wsj_0004.dp',\n",
       " 'wsj_0144.dp',\n",
       " 'wsj_0170.dp',\n",
       " 'wsj_0030.dp',\n",
       " 'wsj_0121.dp',\n",
       " 'wsj_0061.dp',\n",
       " 'wsj_0092.dp',\n",
       " 'wsj_0183.dp',\n",
       " 'wsj_0193.dp',\n",
       " 'wsj_0082.dp',\n",
       " 'wsj_0071.dp',\n",
       " 'wsj_0131.dp',\n",
       " 'wsj_0020.dp',\n",
       " 'wsj_0160.dp',\n",
       " 'wsj_0154.dp',\n",
       " 'wsj_0014.dp',\n",
       " 'wsj_0105.dp',\n",
       " 'wsj_0045.dp']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now get a list of the input documents\n",
    "import os\n",
    "docs = os.listdir('data/dependency_treebank')\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 20, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And split train, dev, and test sets\n",
    "import random\n",
    "random.shuffle(docs)\n",
    "train_docs = docs[:int(0.8*len(docs))]\n",
    "dev_docs = docs[int(0.8*len(docs)):int(0.9*len(docs))]\n",
    "test_docs = docs[int(0.9*len(docs)):]\n",
    "len(train_docs), len(dev_docs), len(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(docs, dir):\n",
    "    \"\"\"\n",
    "    Parse the dependency treebank dataset.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for doc in docs:\n",
    "        np_doc = np.loadtxt(dir+doc, str, delimiter='\\t')\n",
    "        X.append(\" \".join(np_doc[:,0]))\n",
    "        y.append(np_doc[:,1])\n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q9/pjb90yf52j38qcfsync8wf0c0000gn/T/ipykernel_96601/1515543834.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(X),np.array(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Rockwell International Corp. reported flat operating earnings for the fourth quarter ended Sept. 30 . The aerospace , automotive supply , electronics and printing-press concern also indicated that the first half of fiscal 1990 could be rough . In an interview , Donald Beall , chairman , said first-half profit certainly would trail the past year 's , primarily because of weakness in the heavy-truck and passenger-car markets . Still , he added , if the industrial sector remains relatively stable , Rockwell should be able to recover in the second half and about equal fiscal 1989 's operating profit of $ 630.9 million . For fiscal 1989 's fourth quarter , Rockwell 's net income totaled $ 126.1 million , or 50 cents a share . That compares with operating earnings of $ 132.9 million , or 49 cents a share , the year earlier . The prior-year period includes a one-time favorable tax adjustment on the B-1B bomber program and another gain from sale of the industrial sewing-machine business , which made net $ 185.9 million , or 70 cents a share . Sales rose 4 % to $ 3.28 billion from $ 3.16 billion . Mr. Beall said that he was generally pleased with the latest numbers and cited a particularly strong showing by the company 's electronics segment . Overall , pretax electronics earnings soared 12 % to $ 107.9 million from $ 96.4 million . All four areas had higher revenue for the three months ended Sept. 30 . For the year , electronics emerged as Rockwell 's largest sector in terms of sales and earnings , muscling out aerospace for the first time . The graphics business , which also was singled out by the chairman as a positive , saw its operating earnings for the quarter jump 79 % to $ 42.1 million from $ 23.5 million . For the year , bolstered by the introduction of the Colorliner newspaper-printing press , graphics earnings almost doubled . Aerospace earnings sagged 37 % for the quarter and 15 % for the year , largely due to lower B-1B program profit ; the last of the bombers rolled out in April 1988 . That was partially offset by the resumption of space shuttle flights and increased demand for expendable launch-vehicle engines . The company also took hits in the fourth quarters of 1989 and 1988 on a fixed-price weapons-modernization development program -- probably the C-130 gunship , according to analysts . For fiscal 1989 , the company posted net of $ 734.9 million , or $ 2.87 a share , down from $ 811.9 million , or $ 3.04 a share , in fiscal 1988 . Excluding one-time additions to profit in each year , earnings per share were $ 2.47 , up 7.4 % from $ 2.30 in fiscal 1988 . Sales for the year rose 5 % to $ 12.52 billion from $ 11.95 billion in fiscal 1988 .\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = parse_dataset(train_docs, 'data/dependency_treebank/')\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'of', 'to']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "import tensorflow as tf\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(X_train).batch(128)\n",
    "vectorizer.adapt(text_ds)\n",
    "vectorizer.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 200), dtype=int64, numpy=\n",
       "array([[561, 165,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0]])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"acquired chairman\"]])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
       "       -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
       "        0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
       "       -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
       "        0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
       "       -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
       "        0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
       "        0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
       "       -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
       "       -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
       "       -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
       "       -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
       "       -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
       "       -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
       "       -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
       "        0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
       "       -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings_index = {}\n",
    "embedding_dim = 100\n",
    "with open(\"glove.6B.\"+str(embedding_dim) + \"d.txt\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "embeddings_index[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "embedding_matrix = np.zeros((len(vocabulary)+2, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    len(vocabulary)+2, # Number of tokens in the vocabulary\n",
    "    embedding_dim, # Dimensions of the embedding\n",
    "    embeddings_initializer=initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         908900    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               34048     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 943,013\n",
      "Trainable params: 34,113\n",
      "Non-trainable params: 908,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/simone/UniBO/Lab/NLP/Assignment1/GloVe_tests.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simone/UniBO/Lab/NLP/Assignment1/GloVe_tests.ipynb#ch0000015?line=0'>1</a>\u001b[0m X_train \u001b[39m=\u001b[39m vectorizer(np\u001b[39m.\u001b[39marray([[s] \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m X_train]))\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/simone/UniBO/Lab/NLP/Assignment1/GloVe_tests.ipynb#ch0000015?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=99'>100</a>\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=100'>101</a>\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=101'>102</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "X_train = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rockwell'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()[2031]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63e28586807c6502c782d898cf9a0cc5787bb3d77952b17b51ec8bdcd4044a3d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nlp1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
