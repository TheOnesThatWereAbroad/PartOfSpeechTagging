{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.grammar import DependencyGrammar\n",
    "from nltk.parse.dependencygraph import DependencyGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package dependency_treebank to\n",
      "[nltk_data]     /Users/simone/nltk_data...\n",
      "[nltk_data]   Package dependency_treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('dependency_treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(will\n",
      "  (Vinken Pierre , (old (years 61)) ,)\n",
      "  (join (board the) (as (director a nonexecutive)) (Nov. 29))\n",
      "  .)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import dependency_treebank\n",
    "t = dependency_treebank.parsed_sents()\n",
    "print(t[0].tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can download the GloVe embeddings to vectorize our data.\n",
    "\n",
    "**Uncomment to actually download!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wsj_0095.dp',\n",
       " 'wsj_0184.dp',\n",
       " 'wsj_0177.dp',\n",
       " 'wsj_0037.dp',\n",
       " 'wsj_0126.dp',\n",
       " 'wsj_0066.dp',\n",
       " 'wsj_0052.dp',\n",
       " 'wsj_0112.dp',\n",
       " 'wsj_0003.dp',\n",
       " 'wsj_0143.dp',\n",
       " 'wsj_0153.dp',\n",
       " 'wsj_0013.dp',\n",
       " 'wsj_0102.dp',\n",
       " 'wsj_0042.dp',\n",
       " 'wsj_0076.dp',\n",
       " 'wsj_0136.dp',\n",
       " 'wsj_0027.dp',\n",
       " 'wsj_0167.dp',\n",
       " 'wsj_0194.dp',\n",
       " 'wsj_0085.dp',\n",
       " 'wsj_0007.dp',\n",
       " 'wsj_0147.dp',\n",
       " 'wsj_0056.dp',\n",
       " 'wsj_0116.dp',\n",
       " 'wsj_0180.dp',\n",
       " 'wsj_0091.dp',\n",
       " 'wsj_0122.dp',\n",
       " 'wsj_0062.dp',\n",
       " 'wsj_0173.dp',\n",
       " 'wsj_0033.dp',\n",
       " 'wsj_0023.dp',\n",
       " 'wsj_0163.dp',\n",
       " 'wsj_0072.dp',\n",
       " 'wsj_0132.dp',\n",
       " 'wsj_0081.dp',\n",
       " 'wsj_0190.dp',\n",
       " 'wsj_0106.dp',\n",
       " 'wsj_0046.dp',\n",
       " 'wsj_0157.dp',\n",
       " 'wsj_0017.dp',\n",
       " 'wsj_0006.dp',\n",
       " 'wsj_0146.dp',\n",
       " 'wsj_0057.dp',\n",
       " 'wsj_0117.dp',\n",
       " 'wsj_0181.dp',\n",
       " 'wsj_0090.dp',\n",
       " 'wsj_0123.dp',\n",
       " 'wsj_0063.dp',\n",
       " 'wsj_0172.dp',\n",
       " 'wsj_0032.dp',\n",
       " 'wsj_0022.dp',\n",
       " 'wsj_0162.dp',\n",
       " 'wsj_0073.dp',\n",
       " 'wsj_0133.dp',\n",
       " 'wsj_0080.dp',\n",
       " 'wsj_0191.dp',\n",
       " 'wsj_0107.dp',\n",
       " 'wsj_0047.dp',\n",
       " 'wsj_0156.dp',\n",
       " 'wsj_0016.dp',\n",
       " 'wsj_0094.dp',\n",
       " 'wsj_0185.dp',\n",
       " 'wsj_0176.dp',\n",
       " 'wsj_0036.dp',\n",
       " 'wsj_0127.dp',\n",
       " 'wsj_0067.dp',\n",
       " 'wsj_0053.dp',\n",
       " 'wsj_0113.dp',\n",
       " 'wsj_0002.dp',\n",
       " 'wsj_0142.dp',\n",
       " 'wsj_0152.dp',\n",
       " 'wsj_0012.dp',\n",
       " 'wsj_0103.dp',\n",
       " 'wsj_0043.dp',\n",
       " 'wsj_0077.dp',\n",
       " 'wsj_0137.dp',\n",
       " 'wsj_0026.dp',\n",
       " 'wsj_0166.dp',\n",
       " 'wsj_0195.dp',\n",
       " 'wsj_0084.dp',\n",
       " 'wsj_0058.dp',\n",
       " 'wsj_0118.dp',\n",
       " 'wsj_0009.dp',\n",
       " 'wsj_0149.dp',\n",
       " 'wsj_0159.dp',\n",
       " 'wsj_0019.dp',\n",
       " 'wsj_0108.dp',\n",
       " 'wsj_0048.dp',\n",
       " 'wsj_0128.dp',\n",
       " 'wsj_0068.dp',\n",
       " 'wsj_0179.dp',\n",
       " 'wsj_0039.dp',\n",
       " 'wsj_0029.dp',\n",
       " 'wsj_0169.dp',\n",
       " 'wsj_0078.dp',\n",
       " 'wsj_0138.dp',\n",
       " 'wsj_0129.dp',\n",
       " 'wsj_0069.dp',\n",
       " 'wsj_0178.dp',\n",
       " 'wsj_0038.dp',\n",
       " 'wsj_0028.dp',\n",
       " 'wsj_0168.dp',\n",
       " 'wsj_0079.dp',\n",
       " 'wsj_0139.dp',\n",
       " 'wsj_0059.dp',\n",
       " 'wsj_0119.dp',\n",
       " 'wsj_0008.dp',\n",
       " 'wsj_0148.dp',\n",
       " 'wsj_0158.dp',\n",
       " 'wsj_0018.dp',\n",
       " 'wsj_0109.dp',\n",
       " 'wsj_0049.dp',\n",
       " 'wsj_0099.dp',\n",
       " 'wsj_0188.dp',\n",
       " 'wsj_0198.dp',\n",
       " 'wsj_0089.dp',\n",
       " 'wsj_0098.dp',\n",
       " 'wsj_0189.dp',\n",
       " 'wsj_0199.dp',\n",
       " 'wsj_0088.dp',\n",
       " 'wsj_0054.dp',\n",
       " 'wsj_0114.dp',\n",
       " 'wsj_0005.dp',\n",
       " 'wsj_0145.dp',\n",
       " 'wsj_0171.dp',\n",
       " 'wsj_0031.dp',\n",
       " 'wsj_0120.dp',\n",
       " 'wsj_0060.dp',\n",
       " 'wsj_0093.dp',\n",
       " 'wsj_0182.dp',\n",
       " 'wsj_0192.dp',\n",
       " 'wsj_0083.dp',\n",
       " 'wsj_0070.dp',\n",
       " 'wsj_0130.dp',\n",
       " 'wsj_0021.dp',\n",
       " 'wsj_0161.dp',\n",
       " 'wsj_0155.dp',\n",
       " 'wsj_0015.dp',\n",
       " 'wsj_0104.dp',\n",
       " 'wsj_0044.dp',\n",
       " 'wsj_0124.dp',\n",
       " 'wsj_0064.dp',\n",
       " 'wsj_0175.dp',\n",
       " 'wsj_0035.dp',\n",
       " 'wsj_0186.dp',\n",
       " 'wsj_0097.dp',\n",
       " 'wsj_0001.dp',\n",
       " 'wsj_0141.dp',\n",
       " 'wsj_0050.dp',\n",
       " 'wsj_0110.dp',\n",
       " 'wsj_0100.dp',\n",
       " 'wsj_0040.dp',\n",
       " 'wsj_0151.dp',\n",
       " 'wsj_0011.dp',\n",
       " 'wsj_0087.dp',\n",
       " 'wsj_0196.dp',\n",
       " 'wsj_0025.dp',\n",
       " 'wsj_0165.dp',\n",
       " 'wsj_0074.dp',\n",
       " 'wsj_0134.dp',\n",
       " 'wsj_0125.dp',\n",
       " 'wsj_0065.dp',\n",
       " 'wsj_0174.dp',\n",
       " 'wsj_0034.dp',\n",
       " 'wsj_0187.dp',\n",
       " 'wsj_0096.dp',\n",
       " 'wsj_0140.dp',\n",
       " 'wsj_0051.dp',\n",
       " 'wsj_0111.dp',\n",
       " 'wsj_0101.dp',\n",
       " 'wsj_0041.dp',\n",
       " 'wsj_0150.dp',\n",
       " 'wsj_0010.dp',\n",
       " 'wsj_0086.dp',\n",
       " 'wsj_0197.dp',\n",
       " 'wsj_0024.dp',\n",
       " 'wsj_0164.dp',\n",
       " 'wsj_0075.dp',\n",
       " 'wsj_0135.dp',\n",
       " 'wsj_0055.dp',\n",
       " 'wsj_0115.dp',\n",
       " 'wsj_0004.dp',\n",
       " 'wsj_0144.dp',\n",
       " 'wsj_0170.dp',\n",
       " 'wsj_0030.dp',\n",
       " 'wsj_0121.dp',\n",
       " 'wsj_0061.dp',\n",
       " 'wsj_0092.dp',\n",
       " 'wsj_0183.dp',\n",
       " 'wsj_0193.dp',\n",
       " 'wsj_0082.dp',\n",
       " 'wsj_0071.dp',\n",
       " 'wsj_0131.dp',\n",
       " 'wsj_0020.dp',\n",
       " 'wsj_0160.dp',\n",
       " 'wsj_0154.dp',\n",
       " 'wsj_0014.dp',\n",
       " 'wsj_0105.dp',\n",
       " 'wsj_0045.dp']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now get a list of the input documents\n",
    "import os\n",
    "docs = os.listdir('data/dependency_treebank')\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 50, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And split train, dev, and test sets\n",
    "import random\n",
    "random.shuffle(docs)\n",
    "train_docs = docs[:int(0.5*len(docs))]\n",
    "dev_docs = docs[int(0.5*len(docs)):int(0.75*len(docs))]\n",
    "test_docs = docs[int(0.75*len(docs)):]\n",
    "len(train_docs), len(dev_docs), len(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def parse_dataset(docs, dir):\n",
    "    \"\"\"\n",
    "    Parse the dependency treebank dataset.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for doc in docs:\n",
    "        np_doc = np.loadtxt(dir+doc, str, delimiter='\\t')\n",
    "        X.append(\" \".join(np_doc[:,0]))\n",
    "        y.append(\" \".join(np_doc[:,1]))\n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = parse_dataset(train_docs, 'data/dependency_treebank/')\n",
    "X_test, y_test = parse_dataset(test_docs, 'data/dependency_treebank/')\n",
    "X_dev, y_dev = parse_dataset(dev_docs, 'data/dependency_treebank/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 09:45:27.456615: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'of', 'a']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "import tensorflow as tf\n",
    "sequence_length = 500\n",
    "X_vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=sequence_length)\n",
    "X_train_ds = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "X_vectorizer.adapt(X_train_ds)\n",
    "X_vectorizer.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'nn', 'in', 'nnp']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vectorizer = TextVectorization(max_tokens=100, output_sequence_length=sequence_length)\n",
    "y_train_ds = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "y_vectorizer.adapt(y_train_ds)\n",
    "y_vectorizer.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
       "       -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
       "        0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
       "       -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
       "        0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
       "       -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
       "        0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
       "        0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
       "       -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
       "       -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
       "       -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
       "       -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
       "       -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
       "       -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
       "       -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
       "        0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
       "       -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings_index = {}\n",
    "embedding_dim = 100\n",
    "with open(\"glove.6B.\"+str(embedding_dim) + \"d.txt\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "embeddings_index[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = X_vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "embedding_matrix = np.zeros((len(vocabulary)+2, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    len(vocabulary)+2, # Number of tokens in the vocabulary\n",
    "    embedding_dim, # Dimensions of the embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training set\n",
    "X_train = X_vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "y_train = y_vectorizer(np.array([[s] for s in y_train])).numpy()\n",
    "# Transforming y_train into one-hot vectors\n",
    "one_hot_depth = np.max(y_train) + 1\n",
    "y_train = tf.one_hot(y_train, one_hot_depth).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test set\n",
    "X_test = X_vectorizer(np.array([[s] for s in X_test])).numpy()\n",
    "y_test = y_vectorizer(np.array([[s] for s in y_test])).numpy()\n",
    "# Transforming y_test into one-hot vectors\n",
    "y_test = tf.one_hot(y_test, one_hot_depth).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 100)          710100    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 500, 1024)        2510848   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 500, 37)          37925     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 500, 37)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,258,873\n",
      "Trainable params: 3,258,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.InputLayer(input_shape=(sequence_length,)))\n",
    "model.add(embedding_layer)\n",
    "model.add(layers.Bidirectional(layers.LSTM(512, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001))))\n",
    "model.add(layers.TimeDistributed(layers.Dense(one_hot_depth)))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.001),  metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 25s 2s/step - loss: 0.6982 - accuracy: 0.3950 - val_loss: 0.3262 - val_accuracy: 0.4793\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 24s 3s/step - loss: 0.2847 - accuracy: 0.4655 - val_loss: 0.2247 - val_accuracy: 0.4846\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.1961 - accuracy: 0.4660 - val_loss: 0.1588 - val_accuracy: 0.4812\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.1430 - accuracy: 0.4686 - val_loss: 0.1190 - val_accuracy: 0.4823\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.1102 - accuracy: 0.4667 - val_loss: 0.0986 - val_accuracy: 0.4832\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 24s 3s/step - loss: 0.0957 - accuracy: 0.4692 - val_loss: 0.0896 - val_accuracy: 0.4833\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0883 - accuracy: 0.4692 - val_loss: 0.0847 - val_accuracy: 0.4832\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0855 - accuracy: 0.4693 - val_loss: 0.0826 - val_accuracy: 0.4832\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0855 - accuracy: 0.4690 - val_loss: 0.0824 - val_accuracy: 0.4836\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0835 - accuracy: 0.4692 - val_loss: 0.0817 - val_accuracy: 0.4836\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0829 - accuracy: 0.4694 - val_loss: 0.0812 - val_accuracy: 0.4836\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 24s 3s/step - loss: 0.0828 - accuracy: 0.4693 - val_loss: 0.0816 - val_accuracy: 0.4832\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 24s 3s/step - loss: 0.0843 - accuracy: 0.4691 - val_loss: 0.0837 - val_accuracy: 0.4843\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0847 - accuracy: 0.4694 - val_loss: 0.0811 - val_accuracy: 0.4836\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0844 - accuracy: 0.4694 - val_loss: 0.0822 - val_accuracy: 0.4835\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0837 - accuracy: 0.4693 - val_loss: 0.0821 - val_accuracy: 0.4836\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0830 - accuracy: 0.4692 - val_loss: 0.0812 - val_accuracy: 0.4836\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0831 - accuracy: 0.4694 - val_loss: 0.0826 - val_accuracy: 0.4832\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.0861 - accuracy: 0.4690 - val_loss: 0.0839 - val_accuracy: 0.4843\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.0848 - accuracy: 0.4695 - val_loss: 0.0813 - val_accuracy: 0.4836\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 24s 3s/step - loss: 0.0827 - accuracy: 0.4693 - val_loss: 0.0815 - val_accuracy: 0.4836\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 24s 3s/step - loss: 0.0833 - accuracy: 0.4695 - val_loss: 0.0816 - val_accuracy: 0.4832\n",
      "Epoch 23/100\n",
      "5/9 [===============>..............] - ETA: 10s - loss: 0.0815 - accuracy: 0.4896"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/simone/UniBO/Lab/NLP/Assignment1/Baseline.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simone/UniBO/Lab/NLP/Assignment1/Baseline.ipynb#ch0000018?line=0'>1</a>\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/simone/UniBO/Lab/NLP/Assignment1/Baseline.ipynb#ch0000018?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m12\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/nlp1/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=12, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "\n",
      "2\n",
      "4\n",
      "\n",
      "2\n",
      "9\n",
      "\n",
      "2\n",
      "12\n",
      "\n",
      "2\n",
      "9\n",
      "\n",
      "2\n",
      "15\n",
      "\n",
      "2\n",
      "11\n",
      "\n",
      "2\n",
      "8\n",
      "\n",
      "0\n",
      "8\n",
      "\n",
      "0\n",
      "6\n",
      "\n",
      "0\n",
      "7\n",
      "\n",
      "0\n",
      "29\n",
      "\n",
      "0\n",
      "8\n",
      "\n",
      "0\n",
      "8\n",
      "\n",
      "0\n",
      "27\n",
      "\n",
      "0\n",
      "3\n",
      "\n",
      "0\n",
      "8\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "6\n",
      "\n",
      "0\n",
      "7\n",
      "\n",
      "0\n",
      "6\n",
      "\n",
      "0\n",
      "4\n",
      "\n",
      "0\n",
      "8\n",
      "\n",
      "0\n",
      "8\n",
      "\n",
      "0\n",
      "10\n",
      "\n",
      "0\n",
      "3\n",
      "\n",
      "0\n",
      "8\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "7\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "6\n",
      "\n",
      "0\n",
      "6\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "9\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "16\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "15\n",
      "\n",
      "0\n",
      "11\n",
      "\n",
      "0\n",
      "8\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "3\n",
      "\n",
      "0\n",
      "7\n",
      "\n",
      "0\n",
      "3\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "13\n",
      "\n",
      "0\n",
      "14\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "15\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "3\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "7\n",
      "\n",
      "0\n",
      "18\n",
      "\n",
      "0\n",
      "4\n",
      "\n",
      "0\n",
      "8\n",
      "\n",
      "0\n",
      "8\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "19\n",
      "\n",
      "0\n",
      "11\n",
      "\n",
      "0\n",
      "14\n",
      "\n",
      "0\n",
      "3\n",
      "\n",
      "0\n",
      "6\n",
      "\n",
      "0\n",
      "4\n",
      "\n",
      "0\n",
      "7\n",
      "\n",
      "0\n",
      "3\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "9\n",
      "\n",
      "0\n",
      "16\n",
      "\n",
      "0\n",
      "22\n",
      "\n",
      "0\n",
      "3\n",
      "\n",
      "0\n",
      "8\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "9\n",
      "\n",
      "0\n",
      "15\n",
      "\n",
      "0\n",
      "11\n",
      "\n",
      "0\n",
      "6\n",
      "\n",
      "0\n",
      "7\n",
      "\n",
      "0\n",
      "3\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "18\n",
      "\n",
      "0\n",
      "4\n",
      "\n",
      "0\n",
      "4\n",
      "\n",
      "0\n",
      "4\n",
      "\n",
      "0\n",
      "13\n",
      "\n",
      "0\n",
      "4\n",
      "\n",
      "0\n",
      "4\n",
      "\n",
      "0\n",
      "4\n",
      "\n",
      "0\n",
      "4\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "6\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "7\n",
      "\n",
      "0\n",
      "4\n",
      "\n",
      "0\n",
      "9\n",
      "\n",
      "0\n",
      "12\n",
      "\n",
      "0\n",
      "16\n",
      "\n",
      "0\n",
      "15\n",
      "\n",
      "0\n",
      "11\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "3\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "3\n",
      "\n",
      "0\n",
      "5\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, word_tag in enumerate(model.predict(X_test)[0]):\n",
    "    print(np.argmax(word_tag))\n",
    "    print(np.argmax(y_test[0][i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "companies listed below reported quarterly profit substantially different from the average of analysts estimates the companies are followed by at least three analysts and had a minimum fivecent change in actual earnings per share estimated and actual results involving losses are omitted the percent difference compares actual profit with the 30day estimate where at least three analysts have issues forecasts in the past 30 days otherwise actual profit is compared with the 300day estimate                                                                                                                               "
     ]
    }
   ],
   "source": [
    "vocab = X_vectorizer.get_vocabulary()\n",
    "for word in X_train[0]:\n",
    "    print(vocab[word], end=\" \")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63e28586807c6502c782d898cf9a0cc5787bb3d77952b17b51ec8bdcd4044a3d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nlp1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
